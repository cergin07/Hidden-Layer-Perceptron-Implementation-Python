{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wUUE7EVR65PpFp-yK0q5M0pRjkjix29j",
      "authorship_tag": "ABX9TyNnabjUoxousyCTLR9wTxLy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cergin07/Hidden-Layer-Perceptron-Implementation-Python/blob/main/HiddenLayerPerceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ep7wou5oQq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kqTmwEZ5193"
      },
      "source": [
        "X,Y = np.asarray([[-1.1092383 , -0.50740396],\n",
        "       [ 0.00593685, -0.26495218],\n",
        "       [ 0.03905786,  0.3663065 ],\n",
        "       [-0.55352352, -0.06991036],\n",
        "       [ 0.61196954,  0.44753404],\n",
        "       [ 0.34708425,  0.10636916],\n",
        "       [ 0.20490722, -0.09608895],\n",
        "       [ 0.4424715 ,  0.58556814],\n",
        "       [ 0.32799476,  0.43620908],\n",
        "       [ 0.841839  ,  0.01916905],\n",
        "       [ 0.30237804,  1.63850072],\n",
        "       [ 0.28010004,  0.11650101],\n",
        "       [-0.12913466,  0.67194614],\n",
        "       [ 0.72685016,  0.35238476],\n",
        "       [ 0.80883065,  0.162784  ],\n",
        "       [-0.57039888,  0.72065166],\n",
        "       [-0.03922565,  0.59200013],\n",
        "       [ 0.04312138,  0.03676341],\n",
        "       [ 0.995801  ,  0.33832955],\n",
        "       [-0.98072717,  0.31021558],\n",
        "       [ 0.39838621,  1.42691068],\n",
        "       [ 0.37990455, -0.85598519],\n",
        "       [ 1.37781562, -0.62089319],\n",
        "       [-0.8680512 ,  0.37006444],\n",
        "       [-0.86944207, -0.88302328],\n",
        "       [ 0.31973093, -0.92970734],\n",
        "       [ 0.55976953,  0.09183479],\n",
        "       [ 0.0112676 , -0.71061478],\n",
        "       [-0.04391756,  0.46249058],\n",
        "       [ 0.33264352,  0.01572178],\n",
        "       [ 0.63939219, -0.17205565],\n",
        "       [-0.62577591, -0.44700255],\n",
        "       [ 0.33093257,  0.74175236],\n",
        "       [ 0.2167092 ,  0.74691746],\n",
        "       [-0.22384712,  0.32756112],\n",
        "       [-0.41113948,  1.45119633],\n",
        "       [ 0.93275251, -0.44443818],\n",
        "       [ 1.01152575,  0.43082321],\n",
        "       [ 0.63322355, -0.0115863 ],\n",
        "       [-0.23141172, -0.46660888],\n",
        "       [-0.64689759, -0.01273423],\n",
        "       [ 0.44546266,  0.41029104],\n",
        "       [-0.72858388,  0.89690653],\n",
        "       [-1.1004408 , -0.60095327],\n",
        "       [ 1.94717921,  0.18249302],\n",
        "       [-0.29464663, -0.89838376],\n",
        "       [ 0.14452115,  1.42108601],\n",
        "       [-1.38942881, -0.24598292],\n",
        "       [ 0.31846649,  0.04707079],\n",
        "       [ 1.25718801, -0.33581937],\n",
        "       [ 0.92375356, -0.0344655 ],\n",
        "       [ 1.23770566,  0.85732741],\n",
        "       [ 0.91617368,  0.61224776],\n",
        "       [-0.42525923, -0.06848105],\n",
        "       [ 0.07234139,  2.14397784],\n",
        "       [ 0.33783592,  0.08820751],\n",
        "       [-0.08537394,  0.07122336],\n",
        "       [ 0.11677286, -0.23754917],\n",
        "       [ 0.49534772,  0.67529356],\n",
        "       [-0.40985595,  0.5553428 ],\n",
        "       [-0.39164209, -0.13543293],\n",
        "       [ 0.74736849,  0.37844616],\n",
        "       [ 0.27409608, -0.30144127],\n",
        "       [ 0.50930513,  0.32155018],\n",
        "       [ 0.38939831,  0.90864586],\n",
        "       [ 0.05698846, -0.81943676],\n",
        "       [-0.57897544, -0.6147502 ],\n",
        "       [-0.88634671,  0.57643929],\n",
        "       [ 0.72316864,  0.37503695],\n",
        "       [ 0.38749178, -1.95293088],\n",
        "       [ 0.36334996,  0.63658836],\n",
        "       [ 0.16773647, -0.89489337],\n",
        "       [ 1.20715019,  0.29217914],\n",
        "       [ 0.87289026,  0.10473983],\n",
        "       [-0.30347549, -0.06636588],\n",
        "       [-0.52710185,  0.83250406],\n",
        "       [-1.28907078,  1.1973046 ],\n",
        "       [-1.31408848, -0.41725376],\n",
        "       [-0.8701158 , -0.88381606],\n",
        "       [-0.48653429, -1.33858325],\n",
        "       [ 0.88894475,  0.10340347],\n",
        "       [-0.05290566, -0.04946095],\n",
        "       [ 0.04147806,  0.05057636],\n",
        "       [-1.05986991,  0.14652291],\n",
        "       [ 0.62914383,  0.45929266],\n",
        "       [-0.16101255,  0.33430234],\n",
        "       [ 1.18694889,  0.77658892],\n",
        "       [-0.64379194,  0.27827621],\n",
        "       [-1.35665645, -0.59177451],\n",
        "       [ 0.31124201, -0.24695514],\n",
        "       [ 1.08403591,  0.19735247],\n",
        "       [-0.21474478, -0.90933318],\n",
        "       [ 0.31533177,  0.05434951],\n",
        "       [-1.3626198 ,  0.04909903],\n",
        "       [-0.28456372, -0.21934311],\n",
        "       [ 0.38767319, -0.1797269 ],\n",
        "       [ 0.75453246, -0.68205805],\n",
        "       [ 0.70731429,  0.89872712],\n",
        "       [ 0.37806852,  0.98692858],\n",
        "       [ 1.38242012, -0.45019541],\n",
        "       [-0.25143415,  0.21001836],\n",
        "       [-0.88124835, -1.45232314],\n",
        "       [ 0.07452774,  0.32700719],\n",
        "       [-0.44208769,  1.13458887],\n",
        "       [ 0.54777254, -0.72484369],\n",
        "       [ 0.85610586,  0.67436114],\n",
        "       [-1.05261731, -0.50012571],\n",
        "       [-0.62468216,  0.77339386],\n",
        "       [ 1.04651211, -0.0359651 ],\n",
        "       [ 0.0127059 , -0.15694706],\n",
        "       [ 0.402923  , -0.02158426],\n",
        "       [-0.45184556, -0.07226582],\n",
        "       [-0.83657569, -0.56423299],\n",
        "       [-0.09555272,  0.02218829],\n",
        "       [ 1.1954658 , -0.06447883],\n",
        "       [-0.06176276,  0.48959687],\n",
        "       [-0.33523874, -0.53483308],\n",
        "       [-1.11861551, -0.08159154],\n",
        "       [ 0.2849908 ,  0.47983184],\n",
        "       [-0.34260908, -0.85364545],\n",
        "       [ 0.46872065,  0.10264185],\n",
        "       [ 0.16719931,  0.57884876],\n",
        "       [ 0.90393438, -0.20348379],\n",
        "       [-0.41583121,  0.55541419],\n",
        "       [-0.78768408, -1.00624186],\n",
        "       [-0.47322194, -0.63883665],\n",
        "       [ 0.16641566, -0.33391213],\n",
        "       [-0.65640441,  0.2888275 ],\n",
        "       [-1.67651205,  1.22463962],\n",
        "       [-0.08393621,  0.65565946],\n",
        "       [ 0.72995919, -0.68103649],\n",
        "       [-0.42738015, -1.19333953],\n",
        "       [-0.85292022, -0.88616067],\n",
        "       [ 0.09995389, -1.20186511],\n",
        "       [ 0.19057492, -0.79488675],\n",
        "       [-1.06062399,  1.46895238],\n",
        "       [ 0.14708484,  0.73917888],\n",
        "       [ 0.12741831,  0.13565428],\n",
        "       [-0.02511996,  0.86112358],\n",
        "       [-0.12148994, -0.0769814 ],\n",
        "       [ 0.17897453, -0.40255645],\n",
        "       [-0.77052145,  1.49440337],\n",
        "       [ 0.16993849, -1.47830227],\n",
        "       [-0.22636245, -0.22588618],\n",
        "       [ 0.2116879 ,  0.66266423],\n",
        "       [-0.08667134, -0.68953423],\n",
        "       [-0.74934065,  0.45885209],\n",
        "       [-0.54908962, -0.56327766],\n",
        "       [ 0.42909013,  0.54453694],\n",
        "       [-0.27933962,  0.30559751],\n",
        "       [ 0.62958601,  2.35628434],\n",
        "       [ 0.27525617,  0.32733356],\n",
        "       [ 0.06633409,  0.26200449],\n",
        "       [ 0.09550433, -0.38955109],\n",
        "       [ 0.24678737,  0.03683141],\n",
        "       [-1.63382571, -0.80140496],\n",
        "       [ 0.95862738, -0.65492158],\n",
        "       [-0.24208934,  0.56274309],\n",
        "       [ 0.01595292, -0.3782231 ],\n",
        "       [ 0.34074072, -1.07816695],\n",
        "       [ 0.96556459,  0.19957918],\n",
        "       [ 1.04458237,  0.13870632],\n",
        "       [ 0.27230273, -1.21485866],\n",
        "       [-0.20332678, -0.98667666],\n",
        "       [-0.4710314 ,  0.18026184],\n",
        "       [ 0.58255768, -1.06461186],\n",
        "       [-0.89348389, -0.98181532],\n",
        "       [ 0.9524789 , -0.44247814],\n",
        "       [ 0.60800171, -0.15563345],\n",
        "       [-0.2335936 , -0.26108825],\n",
        "       [ 0.11617669, -0.24609483],\n",
        "       [ 0.19940472, -0.40139163],\n",
        "       [ 0.94690872,  0.78875423],\n",
        "       [ 1.36278696, -0.71010284],\n",
        "       [ 1.33018322, -0.75716352],\n",
        "       [ 1.04243906,  1.16484369],\n",
        "       [ 0.03751642, -0.67908721],\n",
        "       [-0.49424057,  0.18095841],\n",
        "       [-1.18665627, -0.21772351],\n",
        "       [ 0.09591472, -0.48058542],\n",
        "       [ 1.24424587, -0.49059754],\n",
        "       [-0.19561091,  0.85609602],\n",
        "       [-0.67132907, -0.93018031],\n",
        "       [ 1.194647  ,  0.19055538],\n",
        "       [ 0.61100894,  0.1745805 ],\n",
        "       [ 0.1741773 ,  1.36902842],\n",
        "       [ 0.36550346,  0.66614359],\n",
        "       [ 0.2021328 ,  0.14058921],\n",
        "       [ 1.04303829, -0.11192665],\n",
        "       [ 0.13551785,  0.10370581],\n",
        "       [ 0.59280737,  0.66313521],\n",
        "       [-0.6701618 , -0.50987246],\n",
        "       [ 1.41843731,  0.98787646],\n",
        "       [ 1.06975718, -0.07396194],\n",
        "       [-0.18502983,  1.61274622],\n",
        "       [-0.38183488,  0.59299563],\n",
        "       [-1.13469068,  1.31697015],\n",
        "       [ 0.01433224,  0.01517787],\n",
        "       [ 1.23779409, -0.64778667],\n",
        "       [ 0.38204079,  0.73463106]]), np.asarray([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
        "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
        "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
        "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
        "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
        "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
        "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
        "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "\n",
        "X, Y = X.T, Y.reshape(1, Y.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UUYojNsFCTV"
      },
      "source": [
        "def to_categorical(x, n_col=None):\n",
        "    \"\"\" One-hot encoding of nominal values \"\"\"\n",
        "    if not n_col:\n",
        "        n_col = np.amax(x) + 1\n",
        "    one_hot = np.zeros((x.shape[0], n_col))\n",
        "    one_hot[np.arange(x.shape[0]), x] = 1\n",
        "    return one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSHYXrAz5_P5"
      },
      "source": [
        "def GetLayerSizes(X,Y):\n",
        "    \n",
        "    sizeX = X.shape[0]\n",
        "    sizeY = Y.shape[0]\n",
        "    \n",
        "    return (sizeX, sizeY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cCxUKz25__U"
      },
      "source": [
        "def InitializeWeightsAndBias(sizeX,sizeH,sizeY):\n",
        "  W=np.random.randn(sizeH,sizeX)*0.01\n",
        "  W0=np.zeros((sizeH,1))\n",
        "  V=np.random.randn(sizeY,sizeH)*0.01\n",
        "  V0=np.zeros((sizeY,1))\n",
        "\n",
        "  parameters = {\"W\":W,\"W0\":W0,\"V\":V,\"V0\":V0}\n",
        "  return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPytjjDO6-OU"
      },
      "source": [
        "def ForwardPropagation(X,parameters):\n",
        "    W = parameters[\"W\"]\n",
        "    W0 = parameters[\"W0\"]\n",
        "    V = parameters[\"V\"]\n",
        "    V0 = parameters[\"V0\"]\n",
        "\n",
        "    Z1=np.dot(W,X)+W0\n",
        "    A1=np.tanh(Z1)\n",
        "    Z2=np.dot(V,A1)+V0\n",
        "    A2=1 / (1 + np.exp(-Z2))\n",
        "\n",
        "    cache = {\"Z1\":Z1,\"A1\":A1,\"Z2\":Z2,\"A2\":A2}\n",
        "    return A2,cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvtxO1rT7l52"
      },
      "source": [
        "def CalculateCost(A2,Y):\n",
        "  m=Y.shape[1]\n",
        "  logprobs = np.multiply(np.log(A2),Y) + np.multiply((1-Y),np.log(1-A2))\n",
        "  cost= -np.sum(logprobs) / m\n",
        "  cost = float(np.squeeze(cost))\n",
        "  return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YScOPo-b8GrH"
      },
      "source": [
        "def BackwardPropagation(parameters,cache,X,Y):\n",
        "  m=Y.shape[1]\n",
        "  W=parameters[\"W\"]\n",
        "  V=parameters[\"V\"]\n",
        "  A1=cache[\"A1\"]\n",
        "  A2=cache[\"A2\"]\n",
        "\n",
        "  derZ2 = A2 - Y\n",
        "  derV = (1/m) * np.dot(derZ2,A1.T)\n",
        "  derV0 = (1/m) * np.sum(derZ2, axis=1, keepdims=True)\n",
        "  \n",
        "  derZ1 = np.dot(V.T,derZ2)*(1 - np.power(A1,2))\n",
        "  derW = (1/m) * np.dot(derZ1,X.T)\n",
        "  derW0 = (1/m)*np.sum(derZ1, axis=1,keepdims=True)\n",
        "\n",
        "  grads={\"derW\":derW,\"derW0\":derW0,\"derV\":derV,\"derV0\":derV0}\n",
        "  return grads\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ7cWOPG9eeU"
      },
      "source": [
        "def UpdateWeightsAndBias(parameters,grads,learningRate=1.2):\n",
        "    W=parameters[\"W\"]\n",
        "    W0=parameters[\"W0\"]\n",
        "    V=parameters[\"V\"]\n",
        "    V0=parameters[\"V0\"]\n",
        "\n",
        "    derW = grads['derW']\n",
        "    derW0 = grads['derW0']\n",
        "    derV = grads['derV']\n",
        "    derV0 = grads['derV0']\n",
        "    \n",
        "    W = W - learningRate * derW\n",
        "    W0 = W0 - learningRate * derW0\n",
        "    V = V - learningRate * derV\n",
        "    V0 = V0 - learningRate * derV0\n",
        "    \n",
        "    parameters = {\"W\": W,\n",
        "                  \"W0\": W0,\n",
        "                  \"V\": V,\n",
        "                  \"V0\": V0}\n",
        "    \n",
        "    return parameters "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uStQXs_h9-om"
      },
      "source": [
        "def Model(X,Y,sizeH,iterationNumber,printCost):\n",
        "  sizeX=GetLayerSizes(X,Y)[0]\n",
        "  sizeY=GetLayerSizes(X,Y)[1]\n",
        "  parameters = InitializeWeightsAndBias(sizeX, sizeH, sizeY)\n",
        "  print(parameters[\"W\"].shape)  \n",
        "  print(parameters[\"W0\"].shape)  \n",
        "  print(parameters[\"V\"].shape)  \n",
        "  print(parameters[\"V0\"].shape)  \n",
        "    # Loop (gradient descent)\n",
        "\n",
        "  for i in range(0, iterationNumber):\n",
        "       \n",
        "      # Forward propagation\n",
        "      A2, cache = ForwardPropagation(X, parameters)\n",
        "      \n",
        "      # Cost function\n",
        "      cost = CalculateCost(A2, Y)\n",
        " \n",
        "      # Backpropagation\n",
        "      grads = BackwardPropagation(parameters, cache, X, Y)\n",
        "\n",
        "      # Gradient descent parameter update\n",
        "      parameters = UpdateWeightsAndBias(parameters, grads)\n",
        "      \n",
        "      # Print the cost every 1000 iterations\n",
        "     \n",
        "      if printCost and i % 1000  == 0:\n",
        "          print (\"Cost after iteration %i: %f\" % (i, cost))\n",
        "\n",
        "  return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMbogVql-oq6",
        "outputId": "8e3336b1-c745-44b5-92d4-224aebdfc436"
      },
      "source": [
        "\n",
        "parameters = Model(X, Y, sizeH = 4, iterationNumber=  10000, printCost=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 2)\n",
            "(4, 1)\n",
            "(1, 4)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693152\n",
            "Cost after iteration 1000: 0.097748\n",
            "Cost after iteration 2000: 0.072447\n",
            "Cost after iteration 3000: 0.068574\n",
            "Cost after iteration 4000: 0.066391\n",
            "Cost after iteration 5000: 0.061588\n",
            "Cost after iteration 6000: 0.067162\n",
            "Cost after iteration 7000: 0.072124\n",
            "Cost after iteration 8000: 0.089584\n",
            "Cost after iteration 9000: 0.084649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8yYFMU_EAid"
      },
      "source": [
        "def predict(parameters,X):\n",
        "    \n",
        "    A2, cache = ForwardPropagation(X,parameters)\n",
        "    predictions = A2>0.5\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY6jhswkEEry",
        "outputId": "af6d3c41-a155-4011-a85c-06ae5101e98d"
      },
      "source": [
        "hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\n",
        "\n",
        "for i, sizeH in enumerate(hidden_layer_sizes):\n",
        "\n",
        "    parameters = Model(X, Y, sizeH, iterationNumber = 5000, printCost=True)\n",
        " \n",
        "    predictions = predict(parameters, X)\n",
        "    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
        "    print (\"Accuracy for {} hidden units: {} %\".format(sizeH, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2)\n",
            "(1, 1)\n",
            "(1, 1)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693147\n",
            "Cost after iteration 1000: 0.558880\n",
            "Cost after iteration 2000: 0.555526\n",
            "Cost after iteration 3000: 0.554677\n",
            "Cost after iteration 4000: 0.554319\n",
            "Accuracy for 1 hidden units: 68.5 %\n",
            "(2, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693148\n",
            "Cost after iteration 1000: 0.389337\n",
            "Cost after iteration 2000: 0.385535\n",
            "Cost after iteration 3000: 0.384641\n",
            "Cost after iteration 4000: 0.384267\n",
            "Accuracy for 2 hidden units: 82.0 %\n",
            "(3, 2)\n",
            "(3, 1)\n",
            "(1, 3)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693148\n",
            "Cost after iteration 1000: 0.106947\n",
            "Cost after iteration 2000: 0.077352\n",
            "Cost after iteration 3000: 0.070593\n",
            "Cost after iteration 4000: 0.070768\n",
            "Accuracy for 3 hidden units: 98.0 %\n",
            "(4, 2)\n",
            "(4, 1)\n",
            "(1, 4)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693151\n",
            "Cost after iteration 1000: 0.100740\n",
            "Cost after iteration 2000: 0.073887\n",
            "Cost after iteration 3000: 0.072700\n",
            "Cost after iteration 4000: 0.071244\n",
            "Accuracy for 4 hidden units: 98.0 %\n",
            "(5, 2)\n",
            "(5, 1)\n",
            "(1, 5)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693148\n",
            "Cost after iteration 1000: 0.090472\n",
            "Cost after iteration 2000: 0.052213\n",
            "Cost after iteration 3000: 0.032802\n",
            "Cost after iteration 4000: 0.026359\n",
            "Accuracy for 5 hidden units: 100.0 %\n",
            "(20, 2)\n",
            "(20, 1)\n",
            "(1, 20)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693129\n",
            "Cost after iteration 1000: 0.091430\n",
            "Cost after iteration 2000: 0.074557\n",
            "Cost after iteration 3000: 0.080529\n",
            "Cost after iteration 4000: 0.075523\n",
            "Accuracy for 20 hidden units: 94.5 %\n",
            "(50, 2)\n",
            "(50, 1)\n",
            "(1, 50)\n",
            "(1, 1)\n",
            "Cost after iteration 0: 0.693146\n",
            "Cost after iteration 1000: 0.098539\n",
            "Cost after iteration 2000: 0.894373\n",
            "Cost after iteration 3000: 0.076538\n",
            "Cost after iteration 4000: 0.068124\n",
            "Accuracy for 50 hidden units: 94.5 %\n"
          ]
        }
      ]
    }
  ]
}